{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dbf9e46f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:06.077414Z",
     "start_time": "2024-01-29T14:56:06.074172Z"
    }
   },
   "outputs": [],
   "source": [
    "#All important library imports go here\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.signal import find_peaks, peak_prominences\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23ff6d",
   "metadata": {},
   "source": [
    "# Line Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f926ecd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:06.082805Z",
     "start_time": "2024-01-29T14:56:06.078419Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# getting the names of all the paragraph images in the directory files\n",
    "filenames=os.listdir('Train')\n",
    "#stripping the extension of the image file from the string of the filename for further use\n",
    "filenames_split=[filename.replace('.tif', '') for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d8391869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:06.086813Z",
     "start_time": "2024-01-29T14:56:06.083811Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def thresholding(image, threshold): #2 tone\n",
    "    ret, thresh= cv2.threshold(image,threshold,255,cv2.THRESH_BINARY_INV)\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c666114a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:06.093193Z",
     "start_time": "2024-01-29T14:56:06.087816Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def directionalHistogram(img, direction):\n",
    "  #function to compute the intensity histograms of an image in x and y directions\n",
    "    (w,h) = img.shape\n",
    "    sum = []\n",
    "    pixel_count=0\n",
    "    \n",
    "    if direction == 'V':\n",
    "        for j in range(h-1):\n",
    "            for i in range(w-1):\n",
    "                pixel = img[i,j]\n",
    "                if(pixel == 255):\n",
    "                    pixel_count+=1\n",
    "            sum.append(pixel_count)\n",
    "            pixel_count=0\n",
    "\n",
    "    if direction == 'H':\n",
    "        for j in range(w-1):\n",
    "            for i in range(h-1):\n",
    "                pixel=img[j,i]\n",
    "                if(pixel==255):\n",
    "                    pixel_count+=1\n",
    "            sum.append(pixel_count)\n",
    "            pixel_count=0\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e229f26d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:06.098216Z",
     "start_time": "2024-01-29T14:56:06.094704Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def smoothHist(hist,kernel_size):\n",
    "    \n",
    "    # A function to smooth out the noise in intensity histograms of an image\n",
    "    \n",
    "    kernel = np.ones(kernel_size) / kernel_size\n",
    "        \n",
    "    return np.convolve(hist, kernel, mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5459eeb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:06.104286Z",
     "start_time": "2024-01-29T14:56:06.099772Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def peakinterp(interp_factor, hist, prominence_factor):\n",
    "    \n",
    "    #Given an intensity histogram of an image, this function increases the resolution of the histogram\n",
    "    #by interpolation and then finds the sharp peaks in this histogram using find_peaks()\n",
    "    #Interp factor controls the new resolution of the histogram\n",
    "    #Prominence factor decides how much the targeted peaks stand out from the baseline of the spectrum\n",
    "    \n",
    "    new_pixel_space = np.linspace(0, interp_factor*len(hist)-1,interp_factor*len(hist))*(1/interp_factor)\n",
    "    pixel_space = np.linspace(0, len(hist)-1, len(hist))\n",
    "    hist_interp = np.interp(new_pixel_space, pixel_space, hist)\n",
    "    \n",
    "    peaks, properties = find_peaks(hist_interp, prominence=np.max(hist_interp)/prominence_factor, width=50)\n",
    "    \n",
    "    return (peaks,hist_interp, new_pixel_space, pixel_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "38f0659e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:06.109213Z",
     "start_time": "2024-01-29T14:56:06.105300Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def gradientSign(hist_interp, resampled_pixel_space, Original_pixel_space):\n",
    "    \n",
    "    #Given an interpolated intensity histogram, this function finds the 1st derivative\n",
    "    # of this histogram and outputs a vector of ones and zeros determining the sign\n",
    "    # of the calculated derivative.\n",
    "    # When the sign is +ve, the vector has 1\n",
    "    # When the sign is -ve, the vector has 0\n",
    "    \n",
    "    hist_grad = np.gradient(hist_interp)\n",
    "    grad_sign = np.where(hist_grad >= 0, 1, 0)\n",
    "    \n",
    "    return grad_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ac460718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:06.115126Z",
     "start_time": "2024-01-29T14:56:06.110218Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def rle(ia):\n",
    "\n",
    "    #A function which when given a sequence of binary values outputs the following:\n",
    "    # 1) the start positions of a portion of repeated values in the sequence\n",
    "    # 2) the length of the portion of repeated values\n",
    "    #This will be useful in dealing with the vector representing the sign change of\n",
    "    #1st derivative of image intensity histogram\n",
    "\n",
    "\n",
    "    n = len(ia)\n",
    "    if n == 0: \n",
    "        return (None, None, None)\n",
    "    else:\n",
    "        y = ia[1:] != ia[:-1]               # check if adjacent points have different gradient signs\n",
    "        i = np.append(np.where(y), n - 1)   # turning points plus last position\n",
    "        z = np.diff(np.append(-1, i))       # length of gap between turning points\n",
    "        p = np.cumsum(np.append(0, z))[:-1] # positions relative to 0\n",
    "        return(z, p, ia[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "37cdc535",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:06.121675Z",
     "start_time": "2024-01-29T14:56:06.116133Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def cutPositions(runlengths, startpositions, values, threshold,interp_factor):\n",
    "    \n",
    "    #Give a vector of ones and zeroes representing the sign change of 1st deriv. of\n",
    "    # a histogram, this function smoothes out the abrupt changes in gradient sign\n",
    "    # which might be an artifact of the gradient calculation.\n",
    "\n",
    "    # This function also gives an estimation of the possible cutting locations to\n",
    "    # extract lines\n",
    "    \n",
    "    viable_index=0\n",
    "    for i in range(len(runlengths)):\n",
    "        current_length=runlengths[i]\n",
    "        if(current_length<threshold): #checking if current line height is less than the chosen threshold\n",
    "            values[i]=values[viable_index]\n",
    "        viable_index=i\n",
    "        \n",
    "    new_hist=[]\n",
    "    for i in range(len(startpositions)):\n",
    "        if(values[i]):\n",
    "            new_hist+=np.ones(runlengths[i]-1).tolist()\n",
    "        else:\n",
    "            new_hist+=np.zeros(runlengths[i]-1).tolist()\n",
    "\n",
    "    cutpos=[]\n",
    "    for i in range(1,len(startpositions)):\n",
    "        last=values[i-1]\n",
    "        current=values[i]\n",
    "        \n",
    "        if(last==0 and current==1):\n",
    "            cutpos.append(startpositions[i])\n",
    "        elif(last==1 and i==1):\n",
    "            cutpos.append(0)\n",
    "\n",
    "    return (cutpos, new_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1c1cc16d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:06.128361Z",
     "start_time": "2024-01-29T14:56:06.122682Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def optimalThreshold(cutpos, runlengths, startpositions, values, new_hist, peaks, init_threshold, interp_factor):\n",
    "\n",
    "    #when removing noise from the gradient sign vector prior to determining the cut locations, we use a threshold\n",
    "    #value on the run lengths of ones and zeros.\n",
    "    #An optimal value of the threshold is the value which when used gives us as many cut locations as detected peaks\n",
    "    # in the original histogram\n",
    "    \n",
    "    while((len(cutpos)!= len(peaks))):\n",
    "        init_threshold=init_threshold+interp_factor\n",
    "        (cutpos, new_hist)=cutPositions(runlengths, startpositions, values, init_threshold,interp_factor)\n",
    "\n",
    "    (cutpos, new_hist)=cutPositions(runlengths, startpositions, values, np.abs(init_threshold-interp_factor),interp_factor)\n",
    "    cutpos=np.array(cutpos)/interp_factor\n",
    "  \n",
    "    return (cutpos, new_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e20fcc8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:06.133258Z",
     "start_time": "2024-01-29T14:56:06.129365Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def cropImageToLines(cutpos, image, direction='H'):\n",
    "    \n",
    "    (w,h)=image.shape\n",
    "    cropped_images=[]\n",
    "\n",
    "    if(direction=='H'):\n",
    "        for i in range(len(cutpos)):\n",
    "            currentpos=cutpos[i]\n",
    "            lastpos=cutpos[i-1]\n",
    "            cropped_images.append(image[lastpos:currentpos-1,0:h-1])\n",
    "    else:\n",
    "        for i in range(len(cutpos)):\n",
    "            currentpos=cutpos[i]\n",
    "            lastpos=cutpos[i-1]\n",
    "            cropped_images.append(image[0:w-1, lastpos:currentpos-1])\n",
    "\n",
    "    return cropped_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f4eef34e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:11.191770Z",
     "start_time": "2024-01-29T14:56:06.134766Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#loop over all pargraph images\n",
    "\n",
    "!mkdir Lines\n",
    "for m in range(len(filenames)):\n",
    "    #print(filenames[m])\n",
    "    #Read the paragraph image and apply thresholding\n",
    "    #image = cv2.imread('ParagraphImages_v1.0/FixedTextParagraphs/Train/'+filenames[m],0)\n",
    "    image = cv2.imread('Train/'+filenames[m],0)\n",
    "    (w,h) = image.shape\n",
    "    thresh1=thresholding(image, 240)\n",
    " \n",
    "\n",
    "    #obtaining horizontal histogram and smoothing it\n",
    "    hist_horizontal=directionalHistogram(thresh1, 'H')\n",
    "    hist_horizontal_smooth=smoothHist(hist_horizontal,17)\n",
    "\n",
    "    #Obtaining peak locations from the smoothed horizontal histogram\n",
    "    init_threshold=50\n",
    "    interp_factor=100\n",
    "    (peaks,smooth_interp, new_pixel_space, pixel_space)=peakinterp(interp_factor, hist_horizontal_smooth, 8)\n",
    "    grad_sign = gradientSign(smooth_interp, new_pixel_space, pixel_space)\n",
    "    #obtaining the piecewise constant function approximating the sign change behavior of the 1st derivative of the horizontal histogram\n",
    "    runlengths, startpositions, values =rle(grad_sign)\n",
    "    (cutpos, new_hist)=cutPositions(runlengths, startpositions, values, init_threshold, interp_factor)\n",
    "\n",
    "\n",
    "    #Removing undesired sign changes from the piecewise function which are the result of noise or numerical artifiacts, not the desired peaks\n",
    "    cutpos, new_hist=optimalThreshold(cutpos, runlengths, startpositions, values, new_hist, peaks, 50, 100)\n",
    "    #displaying lines extracted from the image\n",
    "    lines= cropImageToLines(cutpos.astype(int), thresh1)\n",
    "    for i in range(len(lines)):\n",
    "        #cv2.imwrite(\"files_segmented/\"+filenames_split[m]+\"_\"+str(i)+\".tif\", lines[i])        \n",
    "        cv2.imwrite(\"Lines/\"+filenames_split[m]+\"_\"+str(i)+\".tif\", lines[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae711c2",
   "metadata": {},
   "source": [
    "# Word Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7f970003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:11.196578Z",
     "start_time": "2024-01-29T14:56:11.193346Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# list the file names inside the folder called lines\n",
    "filenames=os.listdir('Lines/')\n",
    "# strip filenames from the file extension for further use\n",
    "filenames_split=[filename.replace('.tif', '') for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b4caf6f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:11.204089Z",
     "start_time": "2024-01-29T14:56:11.198070Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def cropLineToWords(viable_sequences, image):\n",
    "    \n",
    "    #Given a line image and the cutpositions, this functions return the images of the words contained in a line\n",
    "    \n",
    "    (w, h) = image.shape\n",
    "    words=[]\n",
    "    \n",
    "    for i in range(len(viable_sequences)):\n",
    "        if(i > 0 and i < len(viable_sequences)):\n",
    "            words.append(image[0:w - 1, viable_sequences[i - 1] : viable_sequences[i]])\n",
    "        elif(i == len(viable_sequences) - 1):\n",
    "            words.append(image[0:w - 1, viable_sequences[i] : len(viable_sequences)])\n",
    "            \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "57b4be69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:11.209648Z",
     "start_time": "2024-01-29T14:56:11.205584Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def removeSpaces(words):\n",
    "    words_without_spaces=[]\n",
    "    for i in range(len(words)):\n",
    "        if(np.sum(words[i][:,:]>0)):\n",
    "            words_without_spaces.append(words[i])\n",
    "    return words_without_spaces  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0889eea1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:14.366271Z",
     "start_time": "2024-01-29T14:56:11.211655Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file Words already exists.\n"
     ]
    }
   ],
   "source": [
    "#loop over all the lines in your line images folder\n",
    "\n",
    "!mkdir Words\n",
    "\n",
    "for m in range(len(filenames)):\n",
    "\n",
    "    filename=filenames_split[m]\n",
    "    words=[]\n",
    "\n",
    "    #read the line image in grey-scale\n",
    "    img=cv2.imread('Lines/'+filenames[m], 0)\n",
    "    #get dimensions of the image\n",
    "    (w,h) = img.shape\n",
    "    #compute the intensity histogram in the y-direction\n",
    "    hist=directionalHistogram(img, 'V')\n",
    "    #find the locations where the vertical histogram is zero (background spaces between words)\n",
    "    zero_sites=np.where(np.asarray(hist)==0)\n",
    "    zero_sites=zero_sites[0]\n",
    "\n",
    "    sequences=[]\n",
    "    sequence_start=0\n",
    "\n",
    "    #get the start and end of zero sequences of black spaces in the vertical histogram\n",
    "    for i in range(1,len(zero_sites)):\n",
    "        last_zero=zero_sites[i-1]\n",
    "        current_zero=zero_sites[i]\n",
    "        \n",
    "        if(current_zero!=last_zero+1): #there is a word between these 2 values\n",
    "            sequence_end=last_zero\n",
    "            sequences.append([sequence_start,sequence_end])\n",
    "            sequence_start=current_zero\n",
    "            \n",
    "        if(current_zero==last_zero+1 and i==len(zero_sites)-1): #end of the line\n",
    "            sequence_start=sequence_end\n",
    "            sequence_end=current_zero\n",
    "            sequences.append([sequence_start,sequence_end])\n",
    "            \n",
    "    sequence_lengths=[]\n",
    "    for i in range(len(sequences)): #length of spaces\n",
    "        sequence_lengths.append(sequences[i][1]-sequences[i][0]+1)\n",
    "  \n",
    "\n",
    "    #Threshold the size of the zero sequences (whether it is big enough to consider it as\n",
    "    # an interword spacing or small enough to consider as intraword spacing)\n",
    "    sequence_ratio = np.asarray(sequence_lengths)/w\n",
    "    average_sequence_length = np.sum(sequence_lengths[1:len(sequence_lengths)-1])/len(sequence_lengths) #ignore edge gaps\n",
    "    viable_sequences = []\n",
    "    overlap_factor = 0.75 * average_sequence_length \n",
    "    viable_sequences_unrolled = []\n",
    "    \n",
    "    #used 0 instead of average_sequence_length - overlap_factor to breakdown into letters where possible instead of words\n",
    "    \n",
    "    for i in range(len(sequences)):\n",
    "        if(sequence_lengths[i] >= 0):#average_sequence_length - overlap_factor): #space is between words\n",
    "            viable_sequences.append(sequences[i])\n",
    "            viable_sequences_unrolled.append(sequences[i][0])\n",
    "            viable_sequences_unrolled.append(sequences[i][1])  \n",
    "\n",
    "    viable_sequences_unrolled.append(-1)\n",
    "    if(viable_sequences_unrolled[0] != 0): \n",
    "        viable_sequences_unrolled = [0] + viable_sequences_unrolled\n",
    "    words.append(cropLineToWords(viable_sequences_unrolled, img))\n",
    "\n",
    "    ordered_words=[]\n",
    "\n",
    "    #remove the spaces (word images with blank black background)\n",
    "    for i in range(len(words[0])):\n",
    "        word = words[0][i]\n",
    "        sum = np.sum(words[0][i][:,:])\n",
    "        if(sum):\n",
    "            ordered_words.append(word)\n",
    "        else:\n",
    "            ordered_words.append('space')\n",
    "\n",
    "    #save word images to the word directory\n",
    "    count=0\n",
    "    for i in range(len(ordered_words)):\n",
    "        if(not type(ordered_words[i]) is str):\n",
    "            count+=1\n",
    "            cv2.imwrite(\"Words/\"+filename+'_word'+str(count)+\".tif\", ordered_words[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e58c10",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fc75600a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:14.375885Z",
     "start_time": "2024-01-29T14:56:14.367275Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#list the filenames in the folder containing your dataset\n",
    "filenames=os.listdir('Words/')\n",
    "#strip the file extension from the file names\n",
    "filenames_split=[filename.replace('.tif', '') for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "96b9252c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:14.381824Z",
     "start_time": "2024-01-29T14:56:14.377158Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "image_width = 64\n",
    "image_height = 32\n",
    "def distortion_free_resize(image, img_size=(image_height, image_width)):\n",
    "    #resizing the images without distortion using tensorflow\n",
    "    h,w= img_size\n",
    "    image = tf.image.resize(image, size=(h, w), preserve_aspect_ratio=True)\n",
    "\n",
    "    # Check tha amount of padding needed to be done.\n",
    "    pad_height = h - tf.shape(image)[0]\n",
    "    pad_width = w - tf.shape(image)[1]\n",
    "\n",
    "    # Only necessary if you want to do same amount of padding on both sides.\n",
    "    if pad_height % 2 != 0:\n",
    "        height = pad_height // 2\n",
    "        pad_height_top = height + 1\n",
    "        pad_height_bottom = height\n",
    "    else:\n",
    "        pad_height_top = pad_height_bottom = pad_height // 2\n",
    "\n",
    "    if pad_width % 2 != 0:\n",
    "        width = pad_width // 2\n",
    "        pad_width_left = width + 1\n",
    "        pad_width_right = width\n",
    "    else:\n",
    "        pad_width_left = pad_width_right = pad_width // 2\n",
    "\n",
    "    image = tf.pad(\n",
    "        image,\n",
    "        paddings=[\n",
    "            [pad_height_top, pad_height_bottom],\n",
    "            [pad_width_left, pad_width_right],\n",
    "            [0, 0],],)\n",
    "\n",
    "    image = tf.transpose(image, perm=[1, 0, 2])\n",
    "    image = tf.image.flip_left_right(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "87e919a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:14.394639Z",
     "start_time": "2024-01-29T14:56:14.383832Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def crop_image(image, direction='H'): #function to crop the image in vertical and horizontal directions\n",
    "    \n",
    "    w, h = image.shape\n",
    "    if(w < 10 or h < 10):\n",
    "        return image\n",
    "    \n",
    "    hist = directionalHistogram(image, direction)\n",
    "    flipped_hist = np.flip(hist)\n",
    "\n",
    "    startpos = 0\n",
    "    endpos = 0\n",
    "    \n",
    "    for i in range(len(hist) - 1):\n",
    "        if(hist[i] != 0):\n",
    "            startpos = i\n",
    "            break\n",
    "            \n",
    "    for i in range(len(flipped_hist) - 1):\n",
    "        if(flipped_hist[i] != 0):\n",
    "            endpos = len(flipped_hist) - 1 - i\n",
    "            break\n",
    "            \n",
    "    if endpos == 1 or endpos == 0:\n",
    "        endpos = len(hist) - 1\n",
    "        \n",
    "    diff = np.abs(startpos - endpos)\n",
    "    \n",
    "    if diff <= 2:\n",
    "        if 0 <= startpos - 4:\n",
    "            startpos = startpos - 4\n",
    "        else:\n",
    "            endpos = endpos + 4\n",
    "            \n",
    "    if(direction == 'H'):\n",
    "        if(startpos < endpos):\n",
    "            return image[startpos : endpos, :]\n",
    "        else:\n",
    "            return image[endpos : startpos, :]\n",
    "        \n",
    "    elif(direction == 'V'):\n",
    "        if(startpos < endpos):\n",
    "            return image[:, startpos : endpos]\n",
    "        else:\n",
    "            return image[:, endpos : startpos]\n",
    "        \n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7b4cedc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T14:56:17.251147Z",
     "start_time": "2024-01-29T14:56:14.395646Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mkdir Preprocessed\n",
    "\n",
    "for m in range(len(filenames)):\n",
    "    \n",
    "    # read the image in grey scale\n",
    "    image = cv2.imread('Words/'+filenames[m],0)\n",
    "    \n",
    "    #skeletonize the image\n",
    "    #crop the image to the letter\n",
    "    \n",
    "    image_h_cropped=crop_image(image, 'H')\n",
    "    image_hv_cropped=crop_image(image_h_cropped, 'V')\n",
    "    \n",
    "    nh, nw = image_hv_cropped.shape\n",
    "    if (nh < 30 and nw < 30) or nh < 6 or nw < 6: #ignore punctutation and accidental small marks\n",
    "        continue\n",
    "        \n",
    "    #convert image to RGB because 3 dimensions are required to resize\n",
    "    image_hv_cropped=cv2.cvtColor(image_hv_cropped,cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    #distortionless resize with tensorflow\n",
    "    image=distortion_free_resize(image_hv_cropped)\n",
    "    \n",
    "    #convert image back to np array as grey scale and save it as jpg\n",
    "    image=cv2.cvtColor(image.numpy(),cv2.COLOR_RGB2GRAY)    \n",
    "    image=np.rot90(image)\n",
    "\n",
    "    cv2.imwrite(\"Preprocessed/\"+filenames_split[m]+\".jpg\", image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
